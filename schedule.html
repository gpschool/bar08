---
title: Schedule
layout: default
---

<h2>Workshop Schedule</h2>

<table width="100%">
  <tr>
    <td width="10%" ><a name="walk1"></a>16:30 - 17:30</td>
    <td width="90%"><b>Local Walk</b>
 </td>
 </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="dinner1"></a>19:30 - 21:00</td>
    <td width="90%"><b>Dinner</b>
 </td>
 </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="ghahramani"></a>21:00 - 21:45</td>
    <td width="90%"><b>Should all Machine Learning be Bayesian? Should all Bayesian  models be non-parametric?</b>
[<a href="./slides/1 zoubin.pdf">slides</a>]
 </td>
 </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    <a href="http://learning.eng.cam.ac.uk/zoubin/">Zoubin Ghahramani</a>, <i>University of Cambridge, Cambridge, U.K.</i></td>
  </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    I'll present some thoughts and research directions in Bayesian machine 
learning. I'll contrast black-box approaches to machine learning with
model-based Bayesian statistics. Can we meaningfully create Bayesian 
black-boxes? If so what should the prior be? Is non-parametrics the only 
way to go? Since we often can't control the effect of using approximate 
inference, are coherence arguments meaningless?  How can we convert the 
pagan majority of ML researchers to Bayesianism? If the audience gets 
bored of these philosophical musings, I will switch to talking about our 
latest technical work on Indian buffet processes.
</td>
  </tr>
</table><h3>Saturday 06  September</h3>

<table width="100%">
  <tr>
    <td width="10%" ><a name="breakfast1"></a>07:45 - 08:30</td>
    <td width="90%"><b>Breakfast</b>
 </td>
 </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="intro"></a>08:30 - 09:00</td>
    <td width="90%"><b>Introduction</b>
[<a href="./slides/intro lawrence_welcome.ppt">slides</a>]
 </td>
 </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    <a href="http://www.cs.man.ac.uk/~neill/">Neil Lawrence</a>, <i>University of Manchester, Manchester, U.K.</i></td>
  </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="opper"></a>09:00 - 09:45</td>
    <td width="90%"><b>On the relation between Bayesian inference and certain solvable problems of stochastic control</b>
[<a href="./slides/2 opper.pdf">slides</a>]
 </td>
 </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    Manfred Opper, <i>Technical University, Berlin, Germany</i></td>
  </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    Optimal control for nonlinear stochastic dynamical systems  requires thesolution of a nonlinear PDE, the so - called Hamilton Jacobi Bellman equation.Recently, Bert Kappen [1] and Emanuel Todorov [2] have shown that for certain types of cost functions,  this equationcan be transformed to a linear problem which is mathematically related to a Bayesian estimation problem. This has led to novel efficient algorithms for optimal control of such systems.

<p>I will show a simple proof for this surprising result and discuss some possible implications.

<p>[1] Bert Kappen, A linear theory for control of non-linear stochastic systems Physical Review Letters, vol 95, p 200201(2005).

<p>[2] Emanuel Todorov, General duality between optimal control and estimationTodorov E (2008). Accepted in the 47th IEEE Conference on Decision and Control, <a href="http://www.cogsci.ucsd.edu/~todorov/papers.htm">http://www.cogsci.ucsd.edu/~todorov/papers.htm</a>.
</td>
  </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="discussion2"></a>09:45 - 10:00</td>
    <td width="90%"><b>Questions and Discussion</b>
 </td>
 </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="williams"></a>10:00 - 10:45</td>
    <td width="90%"><b>Multi-task Learning with Gaussian Processes</b>
[<a href="./slides/3 williams.pdf">slides</a>]
 </td>
 </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    <a href="http://www.dai.ed.ac.uk/homes/ckiw/">Chris Williams</a>, <i>University of Edinburgh, Edinburgh, U.K.</i></td>
  </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    We consider the problem of multi-task learning, i.e.  the
setup where there are multiple related prediction problems (tasks),
and we seek to improve predictive performance by sharing information
across the different tasks. We address this problem using Gaussian
process (GP) predictors, using a model that learns a shared
covariance function on input-dependent features and a ``free-form''
covariance matrix that specifies inter-task similarity. We discuss the
application of the method to a number of real-world problems such as
compiler performance prediction and learning robot inverse dynamics.

<p>Joint work with Kian Ming Chai, Edwin Bonilla, Stefan Klanke, Sethu Vijayakumar (Edinburgh) 
</td>
  </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="discussion3"></a>10:45 - 11:00</td>
    <td width="90%"><b>Questions and Discussion</b>
 </td>
 </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="coffee1"></a>11:00 - 11:30</td>
    <td width="90%"><b>Coffee</b>
 </td>
 </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="lawrence"></a>11:30 - 12:15</td>
    <td width="90%"><b>Latent Force Models with Gaussian Processes</b>
[<a href="./slides/4lawrence.pdf">slides</a>]
 </td>
 </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    <a href="http://www.cs.man.ac.uk/~neill/">Neil Lawrence</a>, <i>University of Manchester, Manchester, U.K.</i></td>
  </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    We are used to dealing with the situation where we have a latent
variable. Often we assume this latent variable to be independently
drawn from a distribution, <i>e.g.</i> probabilistic PCA or factor
analysis. This simplification is often extended for temporal data
where tractable Markovian independence assumptions are used
(<i>e.g.</i> Kalman filters or hidden Markov models). 

<p>In this talk we will consider the more general case where the
latent variable is a forcing function in a differential equation
model. We will show how for some simple ordinary differential
equations the latent variable can be dealt with analytically for
particular Gaussian process priors over the latent force. In this talk
we will introduce the general framework, present results in systems
biology preview extensions.

<p>Joint work with Magnus Rattray, Mauricio Alvarez, Pei Gao, Antti
Honkela, David Luengo, Guido Sanguinetti and Michalis Titsias.
</td>
  </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="discussion4"></a>12:15 - 12:30</td>
    <td width="90%"><b>Questions and Discussion</b>
 </td>
 </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="lunch1"></a>12:30 - 13:30</td>
    <td width="90%"><b>Lunch</b>
 </td>
 </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="walk2"></a>13:30 - 16:00</td>
    <td width="90%"><b>Local Walk</b>
 </td>
 </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="rattray"></a>16:00 - 16:45</td>
    <td width="90%"><b>Bayesian learning of sparse factor loadings</b>
[<a href="./slides/rattray.pdf">slides</a>]
 </td>
 </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    <a href="http://www.cs.man.ac.uk/~magnus/">Magnus Rattray</a>, <i>University of Manchester, Manchester, U.K.</i></td>
  </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    Learning sparse structure is useful in many applications. For example, gene regulatory networks are sparsely connected since each gene is typically only regulated by a small number of other genes. In this case factor analysis models with sparse loading matrices have been used to uncover the regulatory network from gene expression data. In this talk I will examine the performance of sparsity priors, such as mixture and L1 priors, by calculating learning curves for Bayesian PCA in the limit of large data dimension. This allows us to address a number of questions e.g. how well can we estimate sparsity using the marginal likelihood when the prior is not well-matched to the data generating process? 
</td>
  </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="discussion5"></a>16:45 - 17:00</td>
    <td width="90%"><b>Questions and Discussion</b>
 </td>
 </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="coffee2"></a>17:00 - 17:30</td>
    <td width="90%"><b>Coffee</b>
 </td>
 </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="sollich"></a>17:30 - 18:15</td>
    <td width="90%"><b>Covariance functions and Bayes errors for GP regression on random graphs</b>
[<a href="./slides/sollich_talk2.pdf">slides</a>]
 </td>
 </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    <a href="http://www.mth.kcl.ac.uk/~psollich/">Peter Sollich</a>, <i>King's College London, U.K.</i></td>
  </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    We consider GP learning of functions defined on the nodes of a random
graph. Covariance functions proposed for this scenario, based on
diffusion processes on the graph, are shown to have some
counter-intuitive properties. In particular, on graphs with tree-like
structure where loops can be neglected (as is typically the case for
randomly generated graphs), the "obvious" limit of a large correlation
length scale does not produce a constant covariance function.

<p>In the second part, we look at Bayes errors for GP regression on graphs
and study how the learning curves depend on the size of the graph, its
connectivity, and the number of training examples.

<p>Joint work with Camille Coti.

</td>
  </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="discussion6"></a>18:15 - 18:30</td>
    <td width="90%"><b>Questions and Discussion</b>
 </td>
 </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="storkey"></a>18:30 - 19:15</td>
    <td width="90%"><b>Bayeswatch</b>
[<a href="./slides/storkey_metabayes.ppt">slides</a>]
 </td>
 </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    <a href="http://homepages.inf.ed.ac.uk/amos/">Amos Storkey</a>, <i>University of Edinburgh, Edinburgh, U.K.</i></td>
  </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    Apart from the obvious problem of doing the sums, there are a number of theoretical difficulties associated with the practical business of using Bayesian methods. This talk will introduce a few of these, including the problem of model correctness (from a subjective Bayes standpoint), the irrelevant reward issue and the problem of monolithic probabilistic models. I will introduce the issues, to get them on the table, and talk about a Bayesian framework for allowing the discussion of these.
</td>
  </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="discussion7"></a>19:15 - 19:30</td>
    <td width="90%"><b>Questions and Discussion</b>
 </td>
 </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="dinner2"></a>19:30 - 21:00</td>
    <td width="90%"><b>Dinner</b>
 </td>
 </tr>
</table><h3>Sunday 07  September</h3>

<table width="100%">
  <tr>
    <td width="10%" ><a name="breakfast1"></a>07:45 - 08:30</td>
    <td width="90%"><b>Breakfast</b>
 </td>
 </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="cornford"></a>08:30 - 08:50</td>
    <td width="90%"><b>The role of mechanistic models in Bayesian inference</b>
[<a href="./slides/Cornford2008.pdf">slides</a>]
 </td>
 </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    <a href="http://wiki.aston.ac.uk/DanCornford/">Dan Cornford</a>, <i>Aston University, Birmingham, U.K.</i></td>
  </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    I'll outline the role of mechanistic models, or simulators, in defining priors in a Bayesian inference setting. In particular I will focus on two main cases: 1) where process based understanding of the system allows us to construct a stochastic simulator for the system - which translates to inference in stochastic processes; 2) where an existing (typically) deterministic mechanistic model exists - which we can then emulate and treat 'correctly' in a Bayesian manner. I will pay special attention to the relation between the simulator and reality, since it is reality that typically is sampled to generate the observations used for inference in the model. I will outline ideas from emulation, and show the challenges I think remain to be solved.

<p>This is joint work with lots of people: Alexis Boukouvalas, Yuan Shen, Michael Vrettas, Manfred Opper and many others in the MUCM project.
</td>
  </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="discussion8"></a>08:50 - 09:00</td>
    <td width="90%"><b>Questions and Discussion</b>
 </td>
 </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="snelson"></a>09:00 - 09:45</td>
    <td width="90%"><b>Probabilistic models for ranking and information extraction</b>
[<a href="./slides/snelson.ppt">slides</a>]
 </td>
 </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    <a href="http://research.microsoft.com/~esnelson/">Ed Snelson</a>, <i>MSR, Cambridge</i></td>
  </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    I will summarize some current approaches to information extraction, which aims to obtain structured information from unstructured text sources such as the web. I will then discuss whether Bayesian modelling may be useful in this area and describe a first attempt at extracting class-attributes from web search query logs. If time remains I will move on to discuss various models for probabilistic ranking, and where possible appropriate Bayesian inference techniques.
</td>
  </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="discussion9"></a>09:45 - 10:00</td>
    <td width="90%"><b>Questions and Discussion</b>
 </td>
 </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="winther"></a>10:00 - 10:45</td>
    <td width="90%"><b>Well-known shortcomings, advantages and computational challenges in Bayesian modelling: a few case stories</b>
[<a href="./slides/Winther.pdf">slides</a>]
 </td>
 </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    <a href="http://www2.imm.dtu.dk/~owi/">Ole Winther</a>, <i>Technical University, Denmark</i></td>
  </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    Bayesian inference can be used to judge the data fit quantitatively
through the marginal likelihood. In many practical cases only one
model is considered and parameter averaging is simply used to avoid
overfitting. I show such an example for a large data set of genomic
sequence tags where we want to predict how many new unique tags we
will find if we perform new sequencing. The two parameter Yor-Pitman
process is used and the results illustrate a few well-known facts:
parameter averaging can be crucial and large data sets will expose the
inadequacy of the model as seen by unrealistically narrow error-bars
on (cross-validated) predictions. This indicates that we should come
up with better models and being able to calculate the marginal
likelihood for these models to perform model selection. In the second
part of the talk I will discuss some of the computational challenges
of calculating marginal likelihoods. Gaussian process classification
is used as an example to illustrate that this is hard even for a
uni-modal posterior.
</td>
  </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="discussion10"></a>10:45 - 11:00</td>
    <td width="90%"><b>Questions and Discussion</b>
 </td>
 </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="coffee3"></a>11:00 - 11:30</td>
    <td width="90%"><b>Coffee</b>
 </td>
 </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="titsias"></a>11:30 - 12:15</td>
    <td width="90%"><b>Variational Model Selection for Sparse Gaussian Process Regression</b>
[<a href="./slides/BARK08titsias.pdf">slides</a>]
 </td>
 </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    <a href="http://www.cs.man.ac.uk/~mtitsias/">Michalis Titsias</a>, <i>University of Manchester, Manchester, U.K.</i></td>
  </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    Model selection for sparse Gaussian process (GP) models is an important
problem that involves the selection of both the inducing/active variables
and the kernel parameters. We describe an auxiliary variational method for
sparse GP regression that jointly learns the inducing variables and kernel
parameters by minimizing the Kullback-Leibler divergence between an
approximate distribution and the true posterior over the latent function
values. The variational distribution is parametrized using an
unconstrained distribution over inducing variables and a conditional GP
prior. This framework allows us to compute a lower bound of the true log
marginal likelihood which can be reliably maximized over the inducing
inputs and the kernel parameters. We will show how we can reformulate
several of the most advanced sparse GP methods, such as the subset of data
(SD), DTC, FITC and PITC method, based on the above framework.

</td>
  </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="discussion11"></a>12:15 - 12:30</td>
    <td width="90%"><b>Questions and Discussion</b>
 </td>
 </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="lunch1"></a>12:30 - 13:30</td>
    <td width="90%"><b>Lunch</b>
 </td>
 </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="murraysmith"></a>13:30 - 14:15</td>
    <td width="90%"><b>Negotiated Interaction : Iterative Inference and Feedback of Intention in HCI</b>
[<a href="./slides/Murray-Smith.pdf">slides</a>]
 </td>
 </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    <a href="http://www.dcs.gla.ac.uk/~rod/">Roderick Murray Smith</a>, <i>University of Glasgow, U.K.</i></td>
  </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    I will talk about an approach to human-computer interaction which makes
the uncertainty in the computer's interpretation of the user's
intentions tangible, supporting efficient and enjoyable interaction. I
will present a 'liquid cursor' demonstration, as an example of making
Bayesian inference concrete and visible, as evidence flows between the
user and computer. I will present some current research challenges which
I hope the BARK audience can engage with, including the use of complex
models to shape interaction dynamics, and in measures of interaction
between agents. Application examples from mobile interaction and Brain
Computer Interaction will be used.
</td>
  </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="discussion12"></a>14:15 - 14:30</td>
    <td width="90%"><b>Questions and Discussion</b>
 </td>
 </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="rasmussen"></a>14:30 - 15:15</td>
    <td width="90%"><b>Bayesian Inference and Learning to Control</b>
 </td>
 </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    <a href="http://learning.eng.cam.ac.uk/carl/">Carl Rasmussen</a>, <i>University of Cambridge, Cambridge, U.K.</i></td>
  </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    Control is usually accomplished in two steps: first identifying the plant dynamics and secondly constructing a controller for this dynamics. However, usually there will be some discrepancy between the actual dynamics and the inferred model (due to approximations, limited range of validity, etc), and the optimal controller for the inferred dynamics may not behave well on the actual plant. In this work, we sidestep these issues by learning a controller based on observations of the real plant: we don't need an explicit identification, and uncertainties in the models and plant are properly integrated out in the Bayesian formalism. We show surprisingly fast learning in illustrative control problems with continuous states and discrete time.

<p>Joint work with Marc P. Deisenroth. 
</td>
  </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="discussion13"></a>15:15 - 15:30</td>
    <td width="90%"><b>Questions and Discussion</b>
 </td>
 </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="discussion14"></a>15:30 - 16:30</td>
    <td width="90%"><b>Washing Up --- Workshop Summary (with Coffee)</b>
 </td>
 </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    <a href="http://research.microsoft.com/~joaquinc/">Joaquin Quino&ntilde;ero Candela</a>, <i>Microsoft Research, Cambridge, U.K.</i></td>
  </tr>
</table>
